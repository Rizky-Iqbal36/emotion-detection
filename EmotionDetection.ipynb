{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
    "from keras.models import Model,Sequential\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for images stuff\n",
    "picture_size = 48\n",
    "expression = \"surprise/\"\n",
    "folder_path_train = \"./images/train/\"\n",
    "folder_path_validation = \"./images/validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying images\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(1,10,1):\n",
    "    plt.subplot(3,3,i)\n",
    "    img = load_img(folder_path_train+expression + os.listdir(folder_path_train+expression)\n",
    "                   [i], target_size=(picture_size, picture_size))\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation data\n",
    "batch_size = 128 # per an iteration\n",
    "\n",
    "def setter(path):\n",
    "    return ImageDataGenerator().flow_from_directory(directory=path,\n",
    "                                             target_size=(picture_size, picture_size),\n",
    "                                             color_mode=\"grayscale\",\n",
    "                                             batch_size=batch_size,\n",
    "                                             class_mode=\"categorical\",\n",
    "                                             shuffle=True\n",
    "                                             )\n",
    "\n",
    "train_set = setter(folder_path_train)\n",
    "\n",
    "test_set = setter(folder_path_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "no_of_classes = 7 # there is 7 emotions on data images\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#1st CNN layer\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(48, 48, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd CNN layer\n",
    "model.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#3rd CNN layer\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#4th CNN layer\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#Fully connected 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(no_of_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model with training and validation data\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"./model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               restore_best_weights=True\n",
    "                               )\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                        factor=0.2,\n",
    "                                        patience=3,\n",
    "                                        verbose=1,\n",
    "                                        min_delta=0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 48\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit_generator(generator=train_set,\n",
    "                              steps_per_epoch=train_set.n//train_set.batch_size,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=test_set,\n",
    "                              validation_steps=test_set.n//test_set.batch_size,\n",
    "                              callbacks=callbacks_list\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Accuracy & Loss\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28d78eac953f5c52da104f6408defe8012ac68448e958d45817d657f1f9071f7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
